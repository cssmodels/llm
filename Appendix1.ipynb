{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 1: Classifying the political belonging of regular people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix 1: This uses ChatGPT to annotate messages from random users, for whom the political affiliation is not a-priori known. This allows validating that the LLM does not merely memorize the political affiliation associated to particular messages.\n",
    "\n",
    "We begin by defining a function that uses ChatGPT to guess the political affiliation of an individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def guess_tweet(tweet, model, temperature):\n",
    "    \"\"\"\n",
    "    Generate a political affiliation guess based on a tweet using a specified language model.\n",
    "\n",
    "    Parameters:\n",
    "    tweet (str): The tweet to be analyzed.\n",
    "    model (str): The language model to use (e.g., 'gpt-4').\n",
    "    temperature (float): The temperature setting for the model.\n",
    "\n",
    "    This function attempts to generate a response to the given tweet by \n",
    "    repeatedly calling the OpenAI API. If an exception occurs (e.g., due to \n",
    "    API instability), it retries up to 50 times, waiting 10 seconds between \n",
    "    attempts. Once a response is successfully obtained, it concatenates the \n",
    "    content of all choices and returns the result.\n",
    "    \"\"\"\n",
    "    print(f\"Guessing tweet: '{tweet}'...\")\n",
    "\n",
    "    response = None\n",
    "    tries = 0\n",
    "    failed = True\n",
    "\n",
    "    # The API is at times unstable, so we catch exceptions and try repeatedly \n",
    "    while failed:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                temperature=temperature,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You will be given a Twitter post from an individual in the United States, sent during the two months preceding the 2020 US presidential election, that is, between September 3rd, 2020, and November 3rd, 2020. Your task is to use your knowledge of US politics to make an educated guess on whether the poster is a Democrat or Republican. Your response MUST BE either 'Democrat' or 'Republican'. If you cannot make an educated guess on the basis of the message, just guess either 'Democrat' or 'Republican'. Do NOT motivate your answer.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"'{tweet}'\"}\n",
    "                ]\n",
    "            )\n",
    "            failed = False  # Successfully obtained a response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Caught exception. Waiting...\")\n",
    "            print(e)\n",
    "            failed = True\n",
    "            tries += 1\n",
    "            time.sleep(10)  # Wait 10 seconds before retrying\n",
    "\n",
    "            if tries > 50:\n",
    "                print(\"Too many failures. Giving up.\")\n",
    "                raise e  # Raise the exception if too many retries\n",
    "\n",
    "    # Concatenate the content of all choices in the response\n",
    "    result = ''\n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content\n",
    "\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now load the messages from regular people, and process them line by line\n",
    "\n",
    "COLUMN = 'gpt4_temp02'\n",
    "sample = pd.read_pickle(\"regularpeoplellm.pkl\")\n",
    "errorcount = 0\n",
    "\n",
    "while True:\n",
    "    # Filter rows that have fewer than 1 entry in the specified column\n",
    "    left = sample.loc[sample[COLUMN].map(len) < 1]\n",
    "    print(f\"There are {len(left)} left to process.\")\n",
    "    \n",
    "    # If no rows are left to process, exit the loop\n",
    "    if len(left) == 0:\n",
    "        print(\"All done!\")\n",
    "        break\n",
    "\n",
    "    # Randomly sample one row from the remaining rows\n",
    "    line = left.sample()\n",
    "    index = line.index.values[0]\n",
    "\n",
    "    # Wait for a second before making the next API call\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        # Call the guess_tweet function with the specified parameters\n",
    "        guess = guess_tweet(line['text'].values[0], model='gpt-4', temperature=0.2)\n",
    "        \n",
    "        # Append the guess to the specified column of the DataFrame\n",
    "        sample[COLUMN][index].append(guess)\n",
    "\n",
    "        print(f\"Guess is: {guess}\")\n",
    "        \n",
    "        # Save the updated DataFrame back to the pickle file\n",
    "        sample.to_pickle(\"randompeople.pkl\")\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f\"Error. Unexpected {err=}, {type(err)=}\")        \n",
    "        if errorcount < 10:\n",
    "            # Increment the error count and continue trying if the error count is below 10\n",
    "            errorcount += 1\n",
    "            print(\"Error running. Will just keep trying though.\")\n",
    "            continue\n",
    "        else:\n",
    "            # If too many errors occur, stop the process and raise the exception\n",
    "            print(\"Too many errors. Giving up.\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomllm = pd.read_pickle('regularpeoplellm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the experts classifications of the same messages\n",
    "randomexpert1 = pd.read_csv('RegularPeopleExpert1.csv')[['ind','label1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomexpert2 = pd.read_csv('RegularPeopleExpert2.csv').rename(columns={'Column1':'ind','label':'label2'})[['ind','label2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge them\n",
    "randommerge = pd.merge(randomexpert1,randomexpert2, on='ind')\n",
    "randommerge = pd.merge(randommerge,randomllm, on='ind')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average distance between model and human classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = [1 if e else 0 for e in randommerge.label1 == randommerge.gpt4_temp02]\n",
    "i1 = stats.t.interval(0.95, len(c1)-1, loc=np.mean(c1), scale=stats.sem(c1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = [1 if e else 0 for e in randommerge.label2 == randommerge.gpt4_temp02]\n",
    "i2 = stats.t.interval(0.95, len(c2)-1, loc=np.mean(c2), scale=stats.sem(c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = [1 if e else 0 for e in randommerge.label1 == randommerge.label2]\n",
    "i0 = stats.t.interval(0.95, len(c0)-1, loc=np.mean(c0), scale=stats.sem(c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot that is in the paper. \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract the data from the dataframe\n",
    "comp = ['LLM vs Expert 2','LLM vs Expert 1','Expert 1 vs Expert 2']\n",
    "means = [np.mean(c2),np.mean(c1),np.mean(c0)]\n",
    "intervals = [(i2[1]-i2[0])/2,(i1[1]-i1[0])/2,(i0[1]-i0[0])/2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 2))\n",
    "ax.errorbar(x=means, y=comp, xerr=intervals, fmt='o', capsize=5, markersize=8, color='black')\n",
    "ax.set_xlabel('Correspondance')\n",
    "ax.set_xlim(0., 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.margins(y=0.3, tight=True)\n",
    "plt.savefig('figure_randompeople.png',dpi=300)\n",
    "plt.savefig('figure_randompeople.eps',dpi=300)\n",
    "plt.savefig('figure_randompeople.pdf',dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
